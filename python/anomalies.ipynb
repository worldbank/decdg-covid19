{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_url   = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/'\n",
    "global_url = base_url + 'csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "us_url     = base_url + 'csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "\n",
    "world = pd.read_csv(global_url)\n",
    "us    = pd.read_csv(us_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look first at what's going on in Canada. The global cases files don't have separate national and province level totals, the national is calculated as the sum of the provinces, so something definitely weird going on there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>4/16/20</th>\n",
       "      <th>4/17/20</th>\n",
       "      <th>4/18/20</th>\n",
       "      <th>4/19/20</th>\n",
       "      <th>4/20/20</th>\n",
       "      <th>4/21/20</th>\n",
       "      <th>4/22/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>1996</td>\n",
       "      <td>2397</td>\n",
       "      <td>2562</td>\n",
       "      <td>2803</td>\n",
       "      <td>2908</td>\n",
       "      <td>3095</td>\n",
       "      <td>3401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>1561</td>\n",
       "      <td>1575</td>\n",
       "      <td>1618</td>\n",
       "      <td>1647</td>\n",
       "      <td>1647</td>\n",
       "      <td>1724</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Grand Princess</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>252</td>\n",
       "      <td>256</td>\n",
       "      <td>257</td>\n",
       "      <td>257</td>\n",
       "      <td>257</td>\n",
       "      <td>257</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>579</td>\n",
       "      <td>606</td>\n",
       "      <td>649</td>\n",
       "      <td>675</td>\n",
       "      <td>721</td>\n",
       "      <td>737</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>9840</td>\n",
       "      <td>10456</td>\n",
       "      <td>11013</td>\n",
       "      <td>11561</td>\n",
       "      <td>12063</td>\n",
       "      <td>12715</td>\n",
       "      <td>13718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>15857</td>\n",
       "      <td>16798</td>\n",
       "      <td>17521</td>\n",
       "      <td>17950</td>\n",
       "      <td>19319</td>\n",
       "      <td>20126</td>\n",
       "      <td>20965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>305</td>\n",
       "      <td>307</td>\n",
       "      <td>313</td>\n",
       "      <td>315</td>\n",
       "      <td>316</td>\n",
       "      <td>320</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>Diamond Princess</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>Northwest Territories</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Province/State  4/16/20  4/17/20  4/18/20  4/19/20  4/20/20  \\\n",
       "35                     Alberta     1996     2397     2562     2803     2908   \n",
       "36            British Columbia     1561     1575     1618     1647     1647   \n",
       "37              Grand Princess       13       13       13       13       13   \n",
       "38                    Manitoba      250      250      253      254      254   \n",
       "39               New Brunswick      117      117      117      118      118   \n",
       "40   Newfoundland and Labrador      252      256      257      257      257   \n",
       "41                 Nova Scotia      579      606      649      675      721   \n",
       "42                     Ontario     9840    10456    11013    11561    12063   \n",
       "43        Prince Edward Island       26       26       26       26       26   \n",
       "44                      Quebec    15857    16798    17521    17950    19319   \n",
       "45                Saskatchewan      305      307      313      315      316   \n",
       "231           Diamond Princess       -1       -1       -1       -1       -1   \n",
       "238                  Recovered        0        0        0        0        0   \n",
       "245      Northwest Territories        5        5        5        5        5   \n",
       "246                      Yukon        8        8        9        9       11   \n",
       "\n",
       "     4/21/20  4/22/20  \n",
       "35      3095     3401  \n",
       "36      1724     1795  \n",
       "37        13       -1  \n",
       "38       255      257  \n",
       "39       118      118  \n",
       "40       257      256  \n",
       "41       737      772  \n",
       "42     12715    13718  \n",
       "43        26       26  \n",
       "44     20126    20965  \n",
       "45       320      326  \n",
       "231       -1       -1  \n",
       "238        0        0  \n",
       "245        5        5  \n",
       "246       11       11  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all columns that look like m/d/yy dates\n",
    "days = list(filter(lambda x: len(x.split('/')) == 3, world.columns))\n",
    "today = days[-1]\n",
    "last_week = days[-7:]\n",
    "\n",
    "world[world['Country/Region']=='Canada'][['Province/State'] + last_week]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe they're using \"-1\" for missing? There's nothing in the docs about it, but that would make sense. I can convert those to NaN easily enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subnational US data ###\n",
    "\n",
    "Here's a quick glance at the negative \"new cases\" data in the US and what that looks like. The subnational US case data come from different files than the global data, so it's entirely possible the subnational and national totals aren't consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4/9/20</th>\n",
       "      <th>4/10/20</th>\n",
       "      <th>4/11/20</th>\n",
       "      <th>4/12/20</th>\n",
       "      <th>4/13/20</th>\n",
       "      <th>4/14/20</th>\n",
       "      <th>4/15/20</th>\n",
       "      <th>4/16/20</th>\n",
       "      <th>4/17/20</th>\n",
       "      <th>4/18/20</th>\n",
       "      <th>4/19/20</th>\n",
       "      <th>4/20/20</th>\n",
       "      <th>4/21/20</th>\n",
       "      <th>4/22/20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Province_State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Nevada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>South Carolina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>-512.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                4/9/20  4/10/20  4/11/20  4/12/20  4/13/20  4/14/20  4/15/20  \\\n",
       "Province_State                                                                 \n",
       "Nevada             NaN    266.0    -20.0    134.0    154.0    144.0     77.0   \n",
       "New Hampshire      NaN      0.0     66.0     44.0     56.0    -63.0    217.0   \n",
       "Puerto Rico        NaN     42.0     63.0    109.0      6.0     20.0     51.0   \n",
       "South Carolina     NaN    274.0    144.0    109.0     71.0    162.0    103.0   \n",
       "Washington         NaN    480.0    315.0    175.0     26.0    164.0    143.0   \n",
       "\n",
       "                4/16/20  4/17/20  4/18/20  4/19/20  4/20/20  4/21/20  4/22/20  \n",
       "Province_State                                                                 \n",
       "Nevada              3.0    310.0    102.0    102.0    102.0    107.0    144.0  \n",
       "New Hampshire       0.0    148.0     55.0     48.0     57.0     43.0     98.0  \n",
       "Puerto Rico        69.0     25.0     50.0     95.0     39.0     46.0    -46.0  \n",
       "South Carolina    275.0    168.0    149.0    129.0     69.0     -7.0    322.0  \n",
       "Washington        115.0    460.0    259.0    202.0    136.0    449.0   -512.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = list(filter(lambda x: len(x.split('/')) == 3, us.columns))\n",
    "today = days[-1]\n",
    "last_2_weeks = days[-14:]\n",
    "\n",
    "states = us.groupby('Province_State').sum()[last_2_weeks]\n",
    "\n",
    "# calculate new cases as difference from previous day\n",
    "nc = states.diff(axis=1)\n",
    "\n",
    "# show states with negative case numbers in the last 2 weeks\n",
    "nc[(nc<0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>1/28/20</th>\n",
       "      <th>1/29/20</th>\n",
       "      <th>1/30/20</th>\n",
       "      <th>1/31/20</th>\n",
       "      <th>...</th>\n",
       "      <th>4/13/20</th>\n",
       "      <th>4/14/20</th>\n",
       "      <th>4/15/20</th>\n",
       "      <th>4/16/20</th>\n",
       "      <th>4/17/20</th>\n",
       "      <th>4/18/20</th>\n",
       "      <th>4/19/20</th>\n",
       "      <th>4/20/20</th>\n",
       "      <th>4/21/20</th>\n",
       "      <th>4/22/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25306.0</td>\n",
       "      <td>27051.0</td>\n",
       "      <td>28680.0</td>\n",
       "      <td>31242.0</td>\n",
       "      <td>32114.0</td>\n",
       "      <td>32491.0</td>\n",
       "      <td>26612.0</td>\n",
       "      <td>25517.0</td>\n",
       "      <td>27710.0</td>\n",
       "      <td>27639.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1/22/20  1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  1/28/20  1/29/20  \\\n",
       "225      NaN      0.0      1.0      0.0      3.0      0.0      0.0      0.0   \n",
       "\n",
       "     1/30/20  1/31/20  ...  4/13/20  4/14/20  4/15/20  4/16/20  4/17/20  \\\n",
       "225      0.0      2.0  ...  25306.0  27051.0  28680.0  31242.0  32114.0   \n",
       "\n",
       "     4/18/20  4/19/20  4/20/20  4/21/20  4/22/20  \n",
       "225  32491.0  26612.0  25517.0  27710.0  27639.0  \n",
       "\n",
       "[1 rows x 92 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's compare the new case totals from the global file to what we get\n",
    "# if we aggregate the state-level data\n",
    "\n",
    "days = list(filter(lambda x: len(x.split('/')) == 3, world.columns))\n",
    "world[world['Country/Region']=='US'][days].diff(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1/22/20      NaN\n",
       "1/23/20        0\n",
       "1/24/20        1\n",
       "1/25/20        0\n",
       "1/26/20        3\n",
       "           ...  \n",
       "4/18/20    32491\n",
       "4/19/20    26612\n",
       "4/20/20    25517\n",
       "4/21/20    27710\n",
       "4/22/20    27639\n",
       "Length: 92, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "days = list(filter(lambda x: len(x.split('/')) == 3, us.columns))\n",
    "us.sum()[days].diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like they match, which means if we treat the negative numbers as NaN then the sum of states will be more than the national total. Is this a problem for the tree map?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
